---
layout: compress
---
<!doctype html>
<html lang="en" class="no-js">

  <head>
    {% include head.html %}
    {% include head/custom.html %}
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>hljs.highlightAll();</script>
    <script>
      html {
            scroll-behavior: smooth; /* å¯ç”¨å¹³æ»‘æ»šåŠ¨ */
        }
    </script>
  </head>
  <body>
    {% include browser-upgrade.html %}
    <div class="masthead">
    <div class="masthead__inner-wrap">
      <div class="masthead__menu">
        <nav id="site-nav" class="greedy-nav">
          <ul class="visible-links">
            <li class="masthead__menu-item masthead__menu-item--lg masthead__menu-home-item"><a href="https://qiyao-wang.github.io/">Homepage</a></li>
            <li class="masthead__menu-item"><a href="https://qiyao-wang.github.io/blogs/">Blogs</a></li>
            <li class="masthead__menu-item"><a href="https://qiyao-wang.github.io/paper_daily/">Paper Daily</a></li>
          </ul>
        </nav>
      </div>
    </div>
  </div>
    <div id="main" role="main">

      <div class="sidebar sticky">
        <div id="toc"></div>
      </div>

      <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
        {% if page.title %}<meta itemprop="headline" content="{{ page.title | markdownify | strip_html | strip_newlines | escape_once }}">{% endif %}
        <div class="page__inner-wrap">
          <section class="page__content" itemprop="text">

            <h1 id="Temperature_TopK_TopP">Three Sampling Methods: Temperature, Top K and Top P</h1>
            <p style="color:gray">Feb. 27, 2025 Â· Qiyao Wang Â· Topic #Decoding</p>
            <h2>Temperature Sampling</h2>
            <p>é€šè¿‡è°ƒæ•´ temperature èƒ½å¤Ÿæ”¹å˜é€‰æ‹©æŸäº› token çš„æ¦‚ç‡åˆ†å¸ƒï¼Œæ”¾å¤§æˆ–å‡å°‘å…¶ä¸­çš„é‡‡æ ·çš„éšæœºæ€§ã€‚ä¸€èˆ¬å…¶å–å€¼èŒƒå›´åœ¨ [0, +âˆ] ä¹‹é—´ï¼Œå½“æ¸©åº¦æ¥è¿‘ 1 æ—¶ï¼Œä¿ç•™åŸå§‹çš„é‡‡æ ·åˆ†å¸ƒï¼›å½“æ¸©åº¦æ¥è¿‘ 0 æ—¶ï¼Œä¼šé€æ¸å˜æˆå•å³°åˆ†å¸ƒï¼Œå³ä¸ Greedy Search ç±»ä¼¼ï¼›è€Œå½“æ¸©åº¦è¶Šå¤§ï¼Œå¦‚ $>1$ï¼Œæç«¯æƒ…å†µè¶‹äº âˆ æ—¶ï¼Œé‡‡æ ·åˆ†å¸ƒä¼šé€æ¸è¶‹äºå‡åŒ€åˆ†å¸ƒã€‚</p>
            <p>å¯¹äºåºåˆ— $\mathbf(x)=(x_1,x_2,...,x_m)$ï¼Œåˆ©ç”¨æ¸©åº¦å‚æ•° $T$ è¿›è¡Œæ”¾ç¼© $\frac{x_i}{T}$ï¼Œä¹‹åè¿›è¡Œ Softmax è®¡ç®—</p>
            $$
            p(x_i)=\frac{e^{\frac{x_i}{T}}}{\sum_j e^{\frac{x_j}{T}}}
            $$
              <p>ä¿®æ”¹åŸºç±» Sampler ä¸­å‡½æ•°</p>
<pre>
<code class="language-python">def get_next_token_prob_logits(self, input_ids:torch.Tensor):
    # ç¦æ­¢è®¡ç®—å›¾ä¸­æ¢¯åº¦çš„è®¡ç®—
    with torch.no_grad():
    logits = self.model(input_ids=input_ids).logits
    # åœ¨æ­¤ä¹‹å‰ï¼Œlogits å½¢çŠ¶ä¸º torch.Size([1, 1, 151936])
    # è·å¾— Tensor çš„æœ€åä¸€ç»´åº¦ torch.Size([151936])
    logits = logits[0, -1, :]
    probs = torch.softmax(logits, dim=-1)
    return probs, logits</code>
</pre>
              <p>Temperatureçš„ç›¸å…³ä»£ç å’Œäº‹ä¾‹</p>
<pre>
<code class="language-python">class RandomTempSampler(Sampler):
    def __call__(self, prompt, max_new_tokens=10, temp: float=0.5):
        predictions = []
        result = prompt
        # generate until max_len
        for i in range(max_new_tokens):
            input_ids = self.encode(result)
            next_token_logits = self.get_next_token_prob_logits(input_ids)[1]
            next_token_logits /= temp
            probs = torch.softmax(next_token_logits, dim=-1)
            # æ ¹æ®æ¦‚ç‡åˆ†å¸ƒéšæœºé‡‡æ ·
            ids = torch.multinomial(probs, num_samples=1).item()
            result += self.decode(ids)
            predictions.append(probs[ids].item)
        return result

    def sample_plot(self, prompt, temp: float=0.5):
        input_ids = self.encode(prompt)

        nex_token_probs = self.get_next_token_prob_logits(input_ids)[1]
        nex_token_probs /= temp
        probs = torch.softmax(nex_token_probs, dim=-1)

        self.plot_scores(probs, title=f"Temperature: {temp}", k=10)</code>
</pre>
              <p>å¯¹äº "the color of sky is" è¿›è¡Œä¸åŒæ¸©åº¦çš„é‡‡æ ·ï¼Œå¦‚ä¸‹é¢ä¸‰å¹…å›¾æ‰€ç¤ºï¼Œå¯ä»¥çœ‹åˆ°ï¼Œéšç€ temperature çš„å˜å¤§ï¼Œåˆ†å¸ƒé€æ¸å‡åŒ€ã€‚</p>
              <figure>
                    <img src="temp-0.1.png" alt="probs">
                    <figcaption>å›¾1ï¼šTemperature 0.1ï¼Œç»“æœä¸º 'The color of sky is blue. The color of the sky is a ( ) of the color of the'</figcaption>
              </figure>

              <figure>
                    <img src="temp-0.9.png" alt="probs">
                    <figcaption>å›¾2ï¼šTemperature 0.9ï¼Œç»“æœä¸º 'The color of sky is dark gray, whose density is a positive integer. Now, choose a random sample'</figcaption>
              </figure>

              <figure>
                    <img src="temp-100.png" alt="probs">
                    <figcaption>å›¾3ï¼šTemperature 100ï¼Œç»“æœä¸º (çœŸçš„æ˜¯ä¹±ç ï¼Œéšæœºæ€§å¤ªå¤§äº†) 'The color of sky is ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ì‚¬ëŒë“¤ğ—±Lights\'].\'" @[coverslandÄ±rÄ±leraseâ›·è¶•ğŸ containing BecStrokeGU'ï¼Œå‡ ä¹å·²ç»ä¸ºå‡åŒ€åˆ†å¸ƒ</figcaption>
              </figure>

              <h2>Top K Sampling</h2>
              <p>Top K é‡‡æ ·åœ¨æ¯ä¸€æ¬¡é€‰æ‹© next token æ—¶ï¼Œåªç¡®ä¿æœ€æœ‰å¯èƒ½çš„ $K$ ä¸ª token èƒ½å¤Ÿè¢«é€‰æ‹©ã€‚å½“ $k=1$ æ—¶ï¼Œé€€åŒ–ä¸º Greedy Searchï¼›å½“ $k=|V|$ æ—¶ï¼Œé€€åŒ–ä¸ºçº¯é‡‡æ ·ã€‚Top K å’Œ Temperature å¯ä»¥ç»“åˆä½¿ç”¨ï¼Œè°ƒæ•´ Top K ä¸­çš„éšæœºæ€§ã€‚</p>
              <p>K çš„ç¡®å®šéœ€è¦ç‰¹åˆ«æ³¨æ„ã€‚K è¾ƒå°æ—¶å¯èƒ½ä¼šå¯¼è‡´æ–‡æœ¬å¤šæ ·æ€§ä¸‹é™ï¼ŒK å¤§æ—¶ä¼šå¯¼è‡´åŒ…å«ä¸åˆé€‚çš„è¯çš„å€™é€‰ã€‚</p>
<pre>
<code class="language-python">class TOPKSampler(Sampler):
    def __call__(self, prompt, max_new_tokens=10, top_k=1, temp: float=0.5):
        predictions = []
        result = prompt
        # generate until max_len
        for i in range(max_new_tokens):
            input_ids = self.encode(result)
            nex_token_logits = self.get_next_token_prob_logits(input_ids)[1]
            nex_token_logits = nex_token_logits / temp
            # ç±»ä¼¼äº maskï¼Œå°†æ¦‚ç‡å°çš„logits æ¢æˆ -inf
            indices_to_remove = nex_token_logits < torch.topk(nex_token_logits,top_k)[0][...,-1, None]
            new_logits = torch.clone(nex_token_logits)
            new_logits[indices_to_remove] = float('-inf')

            probs = torch.softmax(new_logits, dim=-1)
            ids = torch.multinomial(probs, num_samples=1).item()
            result += self.decode(ids)
            predictions.append(probs[ids].item)
        return result

    def sample_plot(self, prompt,top_k=5, temp: float=0.5):
        input_ids = self.encode(prompt)
        next_token_logtis = self.get_next_token_prob_logits(input_ids)[1]
        next_token_logtis = next_token_logtis / temp

        indices_to_remove = next_token_logtis < torch.topk(next_token_logtis,top_k)[0][...,-1, None]
        new_logits = torch.clone(next_token_logtis)
        new_logits[indices_to_remove] = float('-inf')

        probs = torch.softmax(new_logits, dim=-1)
        self.plot_scores(probs, title=f"Temperature: {temp} Top K:{top_k}", k= top_k + int(math.sqrt(top_k)))</code>
</pre>
              <p>å¯¹äº "the color of sky is" è¿›è¡Œå¸¦æœ‰æ¸©åº¦çš„ TopK é‡‡æ ·ï¼Œå…¶ä¸­ $K=10,T=0.5$ æ—¶çš„ç»“æœä¸º "The color of sky is blue. If you want to make the sky appear blue, you can use a certain amount of blue paint. If you want to make the sky appear yellow,"ã€‚</p>
              <p>è°ƒæ•´ä¸åŒçš„æ¸©åº¦ï¼Œå¦‚å›¾4å’Œå›¾5æ‰€ç¤º</p>
              <figure>
                    <img src="topk-10-0.1.png" alt="probs">
                    <figcaption>å›¾4ï¼šTemperature: 0.1, TopK: 10</figcaption>
              </figure>
              <figure>
                    <img src="topk-10-0.9.png" alt="probs">
                    <figcaption>å›¾5ï¼šTemperature: 0.9, TopK: 10</figcaption>
              </figure>
            <h2>Top P Sampling</h2>
              <p>Top P Sampling åˆç§°ä¸ºæ ¸é‡‡æ ·ï¼Œå…¶ä¸ Top K Sampling ç±»ä¼¼ï¼Œé€šè¿‡å¯¹å¯é€‰æ‹©çš„è¯é›†è¿›è¡ŒæŸç§é™åˆ¶ï¼Œæ¥é€‰æ‹©æœ€å°çš„è¯é›†ã€‚Top P Sampling é€šè¿‡é™åˆ¶æœ€å°è¯é›†ä¸­æ‰€æœ‰è¯çš„æ¦‚ç‡å’Œå°äº $p$ æ¥å®ç°åŠ¨æ€è°ƒæ•´å€™é€‰è¯ã€‚</p>
<pre>
<code class="language-python">class NucleusSampler(Sampler):
    def __call__(self, prompt, max_new_tokens=10, p: float=0.7):
        predictions = []
        result = prompt
        # generate until max_len
        for i in range(max_new_tokens):
            input_ids = self.encode(result)
            next_token_logits = self.get_next_token_prob_logits(input_ids)[1]
            sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)
            cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)

            sorted_indices_to_remove = cumulative_probs > p

            # è¿™å¥è¯éœ€è¦æ–Ÿé…Œ
            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()
            sorted_indices_to_remove[..., 0] = 0

            indices_to_remove = sorted_indices[sorted_indices_to_remove]
            new_logits = torch.clone(next_token_logits)
            new_logits[indices_to_remove] = float('-inf')

            scores = torch.softmax(new_logits, dim=-1)
            ids = torch.multinomial(scores, num_samples=1).item()

            result += self.decode(ids)

            predictions.append(scores[ids].item)

        return result

    def sample_plot(self, prompt,p: float=0.7):
        input_ids = self.encode(prompt)
        next_token_logits = self.get_next_token_prob_logits(input_ids)[1]
        sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)
        cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)

        sorted_indices_to_remove = cumulative_probs > p
        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()
        sorted_indices_to_remove[..., 0] = 0

        indices_to_remove = sorted_indices[sorted_indices_to_remove]
        new_logits = torch.clone(sorted_logits)
        new_logits[indices_to_remove] = float('-inf')

        probs = torch.softmax(new_logits, dim=-1)
        self.plot_scores(probs, title=f"P: {p}", k=10)</code>
</pre>
              <p>å¯¹äº "the color of sky is" åœ¨ $p=0.8$ æ—¶çš„è¾“å‡ºç»“æœä¸º "The color of sky is blue. This belongs to\nA. The subject of cognition\nB. The"</p>
              <p>å…¶ä¸­åœ¨ä¸åŒçš„ $p$ å€¼ä¸‹çš„é‡‡æ ·æƒ…å†µå¦‚å›¾6å’Œå›¾7æ‰€ç¤º</p>
              <figure>
                    <img src="topp-0.8.png" alt="probs">
                    <figcaption>å›¾6ï¼šP: 0.8</figcaption>
              </figure>
              <figure>
                    <img src="topp-0.1.png" alt="probs">
                    <figcaption>å›¾7ï¼šP: 0.1</figcaption>
              </figure>

            <h1>Reference</h1>

            <h1>Contact</h1>
            <p>There may be some errors present. If you find any, please feel free to contact me at <code>wangqiyao@mail.dlut.edu.cn</code>. I would appreciate it!</p>

          </section>
        </div>
      </article>
    </div>
    {% include scripts.html %}
    <script>
    // åŠ¨æ€ç”Ÿæˆç›®å½•
    const toc = document.getElementById('toc');
    toc.innerHTML = '<strong>Table of Contents</strong>';

    const ul = document.createElement('ul');
    toc.appendChild(ul);

    // è·å–æ‰€æœ‰æ ‡é¢˜
    const headers = document.querySelectorAll('h1, h2, h3, h4, h5, h6');
    headers.forEach(header => {
        // å¿½ç•¥ h1ï¼Œä¸æ·»åŠ åˆ°ç›®å½•ä¸­
        if (header.tagName === 'H1') return;

        const li = document.createElement('li');
        li.style.marginLeft = `${(parseInt(header.tagName[1]) - 1) * 10}px`;

        const a = document.createElement('a');
        a.href = `#${header.id || header.innerText.replace(/\s+/g, '-').toLowerCase()}`;
        a.textContent = header.innerText;
        a.target = "_self";

        // å¦‚æœæ˜¯ h2ï¼Œä½¿ç”¨é»‘è‰²å®å¿ƒç‚¹
        if (header.tagName === 'H2') {
            li.style.listStyleType = 'disc';  // é»‘è‰²å®å¿ƒåœ†ç‚¹
            a.style.color = 'black';  // h2 ä¸ºé»‘è‰²
        }
        // å¦‚æœæ˜¯ h3ï¼Œä½¿ç”¨ç©ºå¿ƒåœ†ç‚¹
        else if (header.tagName === 'H3') {
            li.style.listStyleType = 'circle';  // ç©ºå¿ƒåœ†ç‚¹
            a.style.color = 'gray';  // h3 ä¸ºç°è‰²
        }
        // å¦‚æœæ˜¯ h4ï¼Œä½¿ç”¨æ–¹å—
        else if (header.tagName === 'H4') {
            li.style.listStyleType = 'square';  // æ–¹å—
            a.style.color = 'gray';  // h4 ä¸ºç°è‰²
        }
        // å¦‚æœæ˜¯ h5 å’Œ h6ï¼Œä½¿ç”¨æ–¹å—
        else {
            li.style.listStyleType = 'square';  // æ–¹å—
            a.style.color = 'gray';  // h5 å’Œ h6 ä¸ºç°è‰²
        }

        if (!header.id) {
            header.id = header.innerText.replace(/\s+/g, '-').toLowerCase();
        }

        li.appendChild(a);
        ul.appendChild(li);
    });
</script>
  </body>
</html>
