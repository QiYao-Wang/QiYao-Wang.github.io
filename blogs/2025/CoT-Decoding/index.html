---
layout: compress
---
<!doctype html>
<html lang="en" class="no-js">

  <head>
    {% include head.html %}
    {% include head/custom.html %}
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>hljs.highlightAll();</script>
    <script>
      html {
            scroll-behavior: smooth; /* å¯ç”¨å¹³æ»‘æ»šåŠ¨ */
        }
    </script>
  </head>
  <body>
    {% include browser-upgrade.html %}
    <div class="masthead">
    <div class="masthead__inner-wrap">
      <div class="masthead__menu">
        <nav id="site-nav" class="greedy-nav">
          <ul class="visible-links">
            <li class="masthead__menu-item masthead__menu-item--lg masthead__menu-home-item"><a href="https://qiyao-wang.github.io/">Homepage</a></li>
            <li class="masthead__menu-item"><a href="https://qiyao-wang.github.io/blogs/">Blogs</a></li>
          </ul>
        </nav>
      </div>
    </div>
  </div>
    <div id="main" role="main">

      <div class="sidebar sticky">
        <div id="toc"></div>
      </div>

      <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
        {% if page.title %}<meta itemprop="headline" content="{{ page.title | markdownify | strip_html | strip_newlines | escape_once }}">{% endif %}
        <div class="page__inner-wrap">
          <section class="page__content" itemprop="text">

            <h1 id="cmu-dlsys-course-homework-0:-implementation-and-reflection">Chain-of-Thought Reasoning without Prompting</h1>
            <p style="color:gray">Jan. 07, 2025 - Jan. XX, 2025 Â· Qiyao Wang Â· Topic #Reasoning</p>

              <p>å¤§æ¨¡å‹çš„æ¨ç†æœ€è¿‘å¾ˆç«ï¼Œæˆ‘ä¸ªäººå¯¹äºæ¨ç†çš„ç†è§£æ˜¯åŸºäºçº¿ç´¢æˆ–å‰é¢çš„æ¨ç†é€»è¾‘ä¸æ–­å‘åæœ‰é€»è¾‘åœ°å»¶ä¼¸ï¼Œè¿™æˆ–è®¸å’Œè‡ªå›å½’çš„å½¢å¼å¾ˆåƒï¼ŒDenny Zhou çš„è¿™ç¯‡è®ºæ–‡<sup>[1]</sup>é€šè¿‡ä¿®æ”¹è´ªå©ªè§£ç ï¼ˆgreedy decodingï¼‰ä¸ºåŸºäº CoT-Decoding çš„æœ‰é€‰æ‹©æ€§çš„ top-k decodingï¼Œä»æ— éœ€æç¤ºï¼ˆwithout promptingï¼‰çš„è§†è§’æ¥æ¢ç´¢æˆ–è§‚å¯Ÿå¤§æ¨¡å‹å†…éƒ¨çš„æ¨ç†ã€‚æœ¬æ–‡å°†é¦–å…ˆè¯¦ç»†ä»‹ç»è¿™ç¯‡è®ºæ–‡ï¼Œä¹‹åè¿›è¡Œä»£ç å®ç°ï¼Œå¸Œæœ›èƒ½åœ¨ä¸€å‘¨å†™å®Œ ğŸ˜ã€‚</p>

              <h1>è®ºæ–‡ç²¾è¯»ä¸æ€è€ƒ</h1>
              <h2>The Introduction of Research Question</h2>
              <p>åœ¨æœ¬æ–‡ä¹‹å‰ï¼Œå¤§éƒ¨åˆ†çš„è®ºæ–‡èšç„¦åœ¨åˆ©ç”¨ Prompting çš„æ–¹å¼æ¥æ¿€å‘ LLMs çš„æ¨ç†èƒ½åŠ›ï¼Œå¦‚ ICL ä¸­çš„ Few-Shot Learning åœ¨æµ‹è¯•é—®é¢˜å‰ç»™å®šå‡ ä¸ªä¸æµ‹è¯•é—®é¢˜ç±»ä¼¼çš„ç¤ºä¾‹ï¼Œè¿™äº›ç¤ºä¾‹ä¸­é€šå¸¸åŒ…å«ç€å¯¹åº”é—®é¢˜è§£å†³æ–¹æ¡ˆçš„æ¨ç†æµç¨‹ï¼Œæ¦‚æ‹¬çš„è¯´å³<strong>ç»™å®šå…·æœ‰ä¸­é—´æ­¥éª¤çš„å°‘æ ·æœ¬æç¤ºï¼ˆFew-Shotï¼‰</strong>ï¼Œæˆ–ä½¿ç”¨é›¶æ ·æœ¬ï¼ˆZero-Shotï¼‰æç¤ºçš„æ–¹å¼æŒ‡å¯¼æ¨¡å‹ç»™å‡ºç›¸åº”çš„ä¸­é—´æ­¥éª¤ï¼Œä¾‹å¦‚ (Nye et.al, 2021<sup>[2,3]</sup>ï¼‰ åœ¨ LLMs å‡ºç°ä¹‹å‰å°±å°è¯•ä½¿ç”¨ XML æ ¼å¼æ¥æŒ‡å¯¼æ¨¡å‹åœ¨ç»™å‡ºæ­£ç¡®ç­”æ¡ˆä¹‹å‰åœ¨ <code>&lt;scratch&gt; computing process &lt;/scratch&gt;</code> ä¸­ç»™å‡ºè®¡ç®—è¿‡ç¨‹ï¼Œä¹‹åå†ç»™å‡ºç­”æ¡ˆï¼Œä»¥åŠåˆ©ç”¨æ˜¾å¼çš„æ€ç»´é“¾æç¤º<sup>[4]</sup> <code>Let's think step by step.</code> æ¿€å‘æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä½¿å¾—å¤§æ¨¡å‹åœ¨è¾“å‡ºæœ€ç»ˆç­”æ¡ˆä¹‹å‰èƒ½å¤Ÿç»™å‡ºä¸€å®šçš„æ¨ç†è¿‡ç¨‹ã€‚é™¤ prompting æ–¹æ³•å¤–ï¼Œè¿˜å¯ä»¥é€šè¿‡ model training æˆ– instruction tuning æ¥æ¿€å‘æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä½†è¿™æ ·çš„æ–¹å¼é€šå¸¸ä¼šä½¿å¾—æ¨¡å‹åœ¨é€šç”¨èƒ½åŠ›ä¸Šäº§ç”Ÿç¾éš¾æ€§é—å¿˜çš„æ•ˆæœï¼Œåœ¨æ•°æ®å±‚é¢ï¼ŒåŸºäºå‚æ•°è®­ç»ƒçš„æ–¹æ³•è¿˜éœ€è¦æ„é€ å¤§é‡çš„ CoT çš„æ¨ç†æ•°æ®ï¼Œæˆæœ¬è¾ƒé«˜ã€‚</p>

              <p>æç¤ºæ–¹æ³•çš„å…³é”®æ˜¯å¦‚ä½•åœ¨å¤§æ¨¡å‹å›ç­”æœ€ç»ˆç­”æ¡ˆä¹‹å‰ç»™å‡ºä¸€å®šçš„æ¨ç†ä¸­é—´è¿‡ç¨‹ï¼ˆintermediate stepsï¼‰ï¼Œè¿™ä¸ªä¸­é—´è¿‡ç¨‹æ˜¯æ¨ç†çš„å…³é”®ã€‚é™¤æç¤ºæ–¹æ³•å¤–ï¼Œä¹Ÿæœ‰åˆ©ç”¨ model training å’Œ instruction tuning æ¥æå‡æ¨¡å‹ç”Ÿæˆä¸­é—´æ­¥éª¤èƒ½åŠ›çš„æ–¹æ³•ï¼Œä½†æ˜¯è¿™æ ·çš„æ–¹æ³•ä¸åŸºäº prompt çš„æ–¹æ³•ï¼Œéƒ½å—é™äº â€œinstruction/promptâ€ï¼Œæœ‰æ—¶å€™éœ€è¦ä¸æ–­åœ°ä¿®ç¼®ä½ ç²¾å¿ƒè®¾è®¡çš„ prompt æ‰æœ‰å¯èƒ½æå‡ä¸€äº›æ€§èƒ½ã€‚æœ¬æ–‡æå‡ºäº†è¿™æ ·çš„é—®é¢˜ï¼Œ<strong>åœ¨æ— éœ€ç²¾å¿ƒè®¾è®¡æç¤ºçš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•æ¿€å‘LLMsçš„æ¨ç†èƒ½åŠ›ï¼Ÿ</strong>ï¼Œä»¥åŠ <strong>å¦‚ä½•æ›´å¥½åœ°ç†è§£æ¨¡å‹è‡ªèº«çš„å†…éƒ¨æ¨ç†èƒ½åŠ›ï¼Ÿ</strong> ä½†å¤§æ¨¡å‹é€šå¸¸å€¾å‘äºç›´æ¥è¾“å‡ºæœ€ç»ˆçš„é—®é¢˜ç»“æœï¼Œæœ¬æ–‡ä»è§£ç è¿‡ç¨‹å‡ºå‘ï¼Œæå‡ºäº†<strong>CoT-decoding</strong>ï¼Œèƒ½å¤Ÿä¸åŸºäºæç¤ºï¼Œæ¿€å‘æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼ˆç”Ÿæˆä¸­é—´çš„æ¨ç†æ­¥éª¤ï¼‰ã€‚</p>

              <h2>CoT-Decoding Methodology</h2>
              <p>ä¸ºäº†åœ¨æ— éœ€ prompting çš„å‰æä¸‹æ¿€å‘æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œæœ¬æ–‡ä» decoding é˜¶æ®µå‡ºå‘ï¼Œå…ˆä¸è€ƒè™‘åŒ…å« top-kã€top-p åŠ temperature åœ¨å†…çš„é‡‡æ ·æ–¹æ³•ï¼Œå¤§è¯­è¨€æ¨¡å‹å¯ä»¥é€šè¿‡ greedy decoding çš„æ–¹å¼æ¥é‡‡æ ·ï¼Œå³æ¯æ¬¡é€‰æ‹©å‡ºç°æ¦‚ç‡æœ€å¤§çš„ Tokenã€‚æœ¬æ–‡çš„åŸºæœ¬æ€è·¯æ˜¯ï¼Œåœ¨ç¬¬ä¸€ä¸ªè§£ç æ­¥ï¼ˆfirst decoding stepï¼‰æ—¶ï¼Œä¸ä»…åªé‡‡æ · greedy decoding å¯¹åº”çš„ Tokenï¼Œè€Œæ˜¯å¼•å…¥è¶…å‚æ•° kï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªè§£ç æ­¥ä¸­ top-k ä¸ª Tokensï¼Œåœ¨åç»­çš„è§£ç æ­¥ä¸­ï¼Œåˆ†åˆ«å¯¹è¯¥ k ä¸ª Token è¿›è¡Œè´ªå©ªè§£ç ï¼Œå¦‚å›¾ 1 æ‰€ç¤ºã€‚</p>
              <figure>
                <img src="Illustration_of_CoT-decoding.jpg" alt="Illustration_of_CoT-decoding-image">
                <figcaption>å›¾1ï¼šCoT-Decoding è§£é‡Š</figcaption>
              </figure>
              <p>åœ¨è·å¾—ç¬¬ä¸€ä¸ªè§£ç æ­¥çš„ k ä¸ª Tokens å¯¹åº”çš„ CoT-Path åï¼Œä¸€ä¸ªå¾ˆè‡ªç„¶çš„é—®é¢˜æ˜¯ï¼š<strong>å¦‚ä½•é€‰æ‹©æ­£ç¡®çš„/æ°å½“çš„ CoT-Pathï¼Ÿ</strong>åœ¨ Self-Consistency<sup>[5]</sup> ä¸­é€šè¿‡èšåˆé‡‡æ ·åçš„ç­”æ¡ˆï¼Œé€‰å‡ºå…¶ä¸­æŠ•ç¥¨æ¬¡æ•°ï¼ˆå‡ºç°æœ€å¤šï¼‰çš„ç­”æ¡ˆä½œä¸ºæœ€ç»ˆçš„ç»“æœï¼Œè¿™æ˜¯ä»ä¸€è‡´æ€§è§’åº¦çœ‹æ¥ååˆ†è‡ªç„¶çš„ã€‚æœ¬æ–‡çš„ CoT-Decoding ä¸ºæ¯æ¡ CoT-Path å¼•å…¥äº†ç½®ä¿¡åº¦ï¼ˆconfidenceï¼‰ï¼Œå…¶ä¸­å…³æ³¨æ¯ä¸ªè§£ç æ­¥éª¤ï¼Œå¯¹äº ç¬¬ $k$ ä¸ª CoT-Path çš„ç½®ä¿¡åº¦è®¡ç®—å¦‚ä¸‹</p>
              $$
              \delta_{k,\text{answer}} = \frac{1}{|\text{answer}|}\sum_{x_t\in\text{answer}}p(x_t^1|x_{< t})-p(x_t^2|x_{< t})
              $$

              <p>å³ï¼Œåœ¨ç»™å®šå‰ $t-1$ ä¸ª Tokens è§£ç ç¬¬ $t$ æ­¥æ—¶ï¼Œç¬¬ $t$ æ­¥ä¸­æ¦‚ç‡æœ€å¤§çš„ä¸¤ä¸ª Token $x_t^1$ å’Œ $x_t^2$ çš„å·®å€¼ï¼Œä»è¯¥ CoT-Path çš„ç¬¬ä¸€ä¸ª Token åˆ°ç»“å°¾ Token çš„è¯¥å·®å€¼ä¹‹å’Œçš„å½’ä¸€åŒ–å³ä¸ºç½®ä¿¡åº¦ã€‚è¿™æ ·çš„å®šä¹‰èƒ½å¤Ÿå¾—åˆ°æ‰€æœ‰è§£ç æ­¥ä¸­é‡‡æ ·è¯¥ Token çš„å¹³å‡ç½®ä¿¡åº¦ï¼Œä½†æ˜¯æˆ‘è®¤ä¸ºï¼ˆä½œè€…åœ¨ç»“è®ºä¸­ä¹Ÿæœ‰æåˆ°ï¼‰è¿™ç§ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•ä¼¼ä¹ä¸å¤ªå‡†ç¡®ï¼Œå› ä¸ºå¹¶ä¸æ˜¯æ‰€æœ‰æ­¥çš„ç½®ä¿¡åº¦éƒ½æ˜¯åŒç­‰é‡è¦ã€‚é€šè¿‡è¯¥ç½®ä¿¡åº¦çš„è®¡ç®—æ–¹å¼ï¼Œæ‰€æœ‰çš„ $k$ ä¸ªè§£ç è·¯å¾„éƒ½èƒ½å¤Ÿè¢«å¯¹åº”çš„ $\Delta$ å€¼è¿›è¡Œæ ‡è®°ã€‚å›¾ 1 ä¸­å³ä¸‹è§’çš„å›¾ä¾‹å¯ä»¥çœ‹åˆ°é¢œè‰²è¶Šæ·±åˆ™ä»£è¡¨è¯¥ CoT-Path çš„ confidence $\Delta$ è¶Šå¤§ï¼Œç”šè‡³è¿™æ ·çš„æŒ‡æ ‡åœ¨è¯¥é—®é¢˜ç¤ºä¾‹ä¸Šä¸ç»“æœçš„æ­£ç¡®æ€§æœ‰ä¸€å®šçš„ç›¸å…³æ€§ï¼Œå³åœ¨æ­£ç¡®ç­”æ¡ˆä¸Šçš„ç½®ä¿¡åº¦å¤§äºé”™è¯¯ç­”æ¡ˆï¼›ä¸ greedy decoding è¿™ç§æ²¡æœ‰ CoT-Path çš„é‡‡æ ·ç»“æœç›¸æ¯”ï¼ŒCoT-Path å…·æœ‰æ›´å¤§çš„ $\Delta$ã€‚åŒæ—¶ä½œè€…é˜æ˜ï¼Œåœ¨ $k=10$ çš„ top-10 è§£ç è·¯å¾„ä¸­æŠ½å–æœ€å¤§ç½®ä¿¡åº¦çš„è·¯å¾„çš„å®éªŒä¸­ï¼Œ88% çš„æ•°æ®éƒ½å­˜åœ¨ CoT-Pathã€‚å¦‚å›¾ 2 æ‰€ç¤ºï¼Œä¸º PaLM-2 æ¨¡å‹åœ¨ GSM8K å’Œ Year Parity æ•°æ®é›†ä¸Šçš„ç¤ºä¾‹ï¼Œå…¶ä¸­æ‹¬å·ä¸­çš„è“è‰²æ•°å­—å³è¡¨ç¤ºå¯¹åº” CoT-Path çš„ç½®ä¿¡åº¦ã€‚</p>
              <figure>
                <img src="example-palm.jpg" alt="example-palm-image">
                <figcaption>å›¾2ï¼šPaLM æ¨¡å‹åœ¨ GSM8K å’Œ Year Parity æ•°æ®é›†ä¸Šçš„ç¤ºä¾‹</figcaption>
              </figure>
              <h2>Findings</h2>
              <p>æœ¬æ–‡ä¸è¿‡å¤šé˜é‡Šå…·ä½“çš„å®éªŒå†…å®¹åŠæ•°æ®é›†ç­‰ï¼Œè€Œæ˜¯ä»¥ä½œè€…æŠ¥å‘Šçš„ç›¸å…³å‘ç°ä¸ºè„‰ç»œå¯¹å®éªŒç»“æœè¿›è¡Œå±•ç¤ºä¸åˆ†æã€‚</p>

              <h1>ä»£ç å¤ç°</h1>

              <h1>Reference</h1>
              <p>[1] Wang X, Zhou D. <a href="https://openreview.net/forum?id=4Zt7S0B0Jp">Chain-of-Thought Reasoning Without Prompting</a> [C]. The Thirty-Eighth Annual Conference on Neural Information Processing Systems (NeurIPS 2024).</p>
              <p>[2] Nye M, Andreassen AJ, Gur-Ari G, et al. <a href="https://openreview.net/forum?id=HBlx2idbkbq">Show Your Work: Scratchpads for Intermediate Computation with Language Models</a> [C]. ICLR, Deep Learning for Code Workshop, 2022.</p>
              <p>[3] Blog: <a href="https://leehanchung.github.io/blogs/2024/10/21/reasoning-inference-scaling/">https://leehanchung.github.io/blogs/2024/10/21/reasoning-inference-scaling/</a></p>
              <p>[4] Wei J, Wang X, Schuurmans D, et al. <a href="https://arxiv.org/abs/2201.11903">Chain-of-thought prompting elicits reasoning in large language models</a>[J]. Advances in neural information processing systems, 2022, 35: 24824-24837.</p>
              <p>[5] Wang X, Wei J, Schuurmans D, et al. Self-Consistency Improves Chain of Thought Reasoning in Language Models[C]. The Eleventh International Conference on Learning Representations.</p>

              <h1>Contact</h1>
              <p>There may be some errors present. If you find any, please feel free to contact me at <code>wangqiyao@mail.dlut.edu.cn</code>. I would appreciate it!</p>

          </section>
        </div>
      </article>
    </div>
    {% include scripts.html %}
    <script>
        // åŠ¨æ€ç”Ÿæˆç›®å½•
        const toc = document.getElementById('toc');
        toc.innerHTML = '<strong>Table of Contents</strong>';

        const ul = document.createElement('ul');
        toc.appendChild(ul);

        // è·å–æ‰€æœ‰æ ‡é¢˜
        const headers = document.querySelectorAll('h1, h2, h3, h4, h5, h6');
        headers.forEach(header => {
            const li = document.createElement('li');
            li.style.marginLeft = `${(parseInt(header.tagName[1]) - 1) * 10}px`;

            const a = document.createElement('a');
            a.href = `#${header.id || header.innerText.replace(/\s+/g, '-').toLowerCase()}`;
            a.textContent = header.innerText;
            a.target="_self";

            if (!header.id) {
                header.id = header.innerText.replace(/\s+/g, '-').toLowerCase();
            }

            li.appendChild(a);
            ul.appendChild(li);
        });
    </script>
  </body>
</html>
